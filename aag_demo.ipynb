{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'start_end_date', 'stock_list']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'data_daily_index_new.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "\n",
    "    print(list(f.keys()))\n",
    "    \n",
    "    df_dic = {}\n",
    "    for key in f.keys():\n",
    "        df_dic[key] = pd.read_hdf(file_path, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data Index(['stock_num', 'factor_k_amount', 'S_DQ_VOLUME', 'S_DQ_AMOUNT',\n",
      "       'S_DQ_ADJVOLUME', 'S_DQ_ADJAMOUNT', 'S_DQ_OPEN', 'S_DQ_HIGH',\n",
      "       'S_DQ_LOW', 'S_DQ_CLOSE', 'BUY_VALUE_EXLARGE_ORDER',\n",
      "       'SELL_VALUE_EXLARGE_ORDER', 'BUY_VALUE_LARGE_ORDER',\n",
      "       'SELL_VALUE_LARGE_ORDER', 'BUY_VALUE_MED_ORDER', 'SELL_VALUE_MED_ORDER',\n",
      "       'BUY_VALUE_SMALL_ORDER', 'SELL_VALUE_SMALL_ORDER', 'S_MFD_INFLOW',\n",
      "       'S_MFD_INFLOW_OPEN', 'OPEN_NET_INFLOW_RATE_VALUE', 'S_MFD_INFLOW_CLOSE',\n",
      "       'CLOSE_NET_INFLOW_RATE_VALUE', 'S_MFD_INFLOW_OPEN_LARGE_ORDER',\n",
      "       'OPEN_NET_INFLOW_RATE_VALUE_L', 'S_MFD_INFLOW_CLOSE_LARGE_ORDER',\n",
      "       'CLOSE_NET_INFLOW_RATE_VALU_L', 'BUY_VALUE_EXLARGE_ORDER_ACT',\n",
      "       'SELL_VALUE_EXLARGE_ORDER_ACT', 'BUY_VALUE_LARGE_ORDER_ACT',\n",
      "       'SELL_VALUE_LARGE_ORDER_ACT', 'BUY_VALUE_MED_ORDER_ACT',\n",
      "       'SELL_VALUE_MED_ORDER_ACT', 'BUY_VALUE_SMALL_ORDER_ACT',\n",
      "       'SELL_VALUE_SMALL_ORDER_ACT'],\n",
      "      dtype='object')                           stock_num  factor_k_amount   S_DQ_VOLUME  \\\n",
      "date     F_INFO_WINDCODE                                             \n",
      "20171009 866005.WI             48.0              1.0  5.297224e+05   \n",
      "         866006.WI             47.0              1.0  8.902616e+05   \n",
      "         866007.WI             29.0              1.0  8.677217e+05   \n",
      "         866008.WI             49.0              1.0  1.112506e+06   \n",
      "         866009.WI             49.0              1.0  1.076683e+06   \n",
      "\n",
      "                           S_DQ_AMOUNT  S_DQ_ADJVOLUME  S_DQ_ADJAMOUNT  \\\n",
      "date     F_INFO_WINDCODE                                                 \n",
      "20171009 866005.WI        5.283243e+08    5.283243e+08    5.283243e+08   \n",
      "         866006.WI        8.927014e+08    8.927014e+08    8.927014e+08   \n",
      "         866007.WI        8.718531e+08    8.718531e+08    8.718531e+08   \n",
      "         866008.WI        1.115838e+09    1.115838e+09    1.115838e+09   \n",
      "         866009.WI        1.083245e+09    1.083245e+09    1.083245e+09   \n",
      "\n",
      "                          S_DQ_OPEN    S_DQ_HIGH    S_DQ_LOW   S_DQ_CLOSE  \\\n",
      "date     F_INFO_WINDCODE                                                    \n",
      "20171009 866005.WI           1000.0  1003.784668  992.281450   994.443561   \n",
      "         866006.WI           1000.0  1007.138383  997.932021  1002.053905   \n",
      "         866007.WI           1000.0  1012.381897  994.000991  1004.193998   \n",
      "         866008.WI           1000.0  1010.784527  993.886073  1006.003954   \n",
      "         866009.WI           1000.0  1012.330824  996.157335  1007.734270   \n",
      "\n",
      "                          ...  S_MFD_INFLOW_CLOSE_LARGE_ORDER  \\\n",
      "date     F_INFO_WINDCODE  ...                                   \n",
      "20171009 866005.WI        ...                     -244.653133   \n",
      "         866006.WI        ...                     -433.711274   \n",
      "         866007.WI        ...                     -496.701548   \n",
      "         866008.WI        ...                      150.085494   \n",
      "         866009.WI        ...                     -149.122429   \n",
      "\n",
      "                          CLOSE_NET_INFLOW_RATE_VALU_L  \\\n",
      "date     F_INFO_WINDCODE                                 \n",
      "20171009 866005.WI                           -0.355721   \n",
      "         866006.WI                            0.126477   \n",
      "         866007.WI                           -0.595890   \n",
      "         866008.WI                            0.379035   \n",
      "         866009.WI                            0.149863   \n",
      "\n",
      "                          BUY_VALUE_EXLARGE_ORDER_ACT  \\\n",
      "date     F_INFO_WINDCODE                                \n",
      "20171009 866005.WI                        6920.682810   \n",
      "         866006.WI                       17422.139426   \n",
      "         866007.WI                       16180.760021   \n",
      "         866008.WI                       23205.938092   \n",
      "         866009.WI                       21890.092151   \n",
      "\n",
      "                          SELL_VALUE_EXLARGE_ORDER_ACT  \\\n",
      "date     F_INFO_WINDCODE                                 \n",
      "20171009 866005.WI                         7027.977244   \n",
      "         866006.WI                        17246.619438   \n",
      "         866007.WI                        11694.469362   \n",
      "         866008.WI                        16445.116671   \n",
      "         866009.WI                        17497.571047   \n",
      "\n",
      "                          BUY_VALUE_LARGE_ORDER_ACT  \\\n",
      "date     F_INFO_WINDCODE                              \n",
      "20171009 866005.WI                      7580.396975   \n",
      "         866006.WI                     12863.740598   \n",
      "         866007.WI                     12698.103907   \n",
      "         866008.WI                     16753.824900   \n",
      "         866009.WI                     15753.460533   \n",
      "\n",
      "                          SELL_VALUE_LARGE_ORDER_ACT  BUY_VALUE_MED_ORDER_ACT  \\\n",
      "date     F_INFO_WINDCODE                                                        \n",
      "20171009 866005.WI                       9978.790687              7062.688481   \n",
      "         866006.WI                      14830.758398              9373.301319   \n",
      "         866007.WI                      13947.031134             11424.143338   \n",
      "         866008.WI                      16118.531112             13334.623467   \n",
      "         866009.WI                      15782.942643             12763.320861   \n",
      "\n",
      "                          SELL_VALUE_MED_ORDER_ACT  BUY_VALUE_SMALL_ORDER_ACT  \\\n",
      "date     F_INFO_WINDCODE                                                        \n",
      "20171009 866005.WI                     7701.865337                3909.487160   \n",
      "         866006.WI                     9870.936368                5176.162949   \n",
      "         866007.WI                    11221.745645                5647.262172   \n",
      "         866008.WI                    12939.333886                7258.685690   \n",
      "         866009.WI                    12347.398153                7038.548327   \n",
      "\n",
      "                          SELL_VALUE_SMALL_ORDER_ACT  \n",
      "date     F_INFO_WINDCODE                              \n",
      "20171009 866005.WI                       3817.618587  \n",
      "         866006.WI                       5168.040474  \n",
      "         866007.WI                       5947.646786  \n",
      "         866008.WI                       7258.678792  \n",
      "         866009.WI                       6975.881157  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "\n",
      "start_end_date Int64Index([0], dtype='int64')           0\n",
      "0  20171001\n",
      "1  20230928\n",
      "\n",
      "\n",
      "stock_list Index(['sign'], dtype='object')                                          sign\n",
      "date     F_INFO_WINDCODE S_CON_WINDCODE      \n",
      "20171009 881006.WI       600415.SH          1\n",
      "         881007.WI       600008.SH          1\n",
      "         882414.WI       900907.SH          1\n",
      "         882119.WI       002558.SZ          1\n",
      "         881302.WI       000661.SZ          1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in df_dic.keys():\n",
    "    print(f'{key}',df_dic[key].columns, df_dic[key].head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      F_INFO_WINDCODE\n",
      "20171009  866005.WI            48.0\n",
      "          866006.WI            47.0\n",
      "          866007.WI            29.0\n",
      "          866008.WI            49.0\n",
      "          866009.WI            49.0\n",
      "                              ...  \n",
      "20230928  WKLI.WI              20.0\n",
      "          WKMM.WI              58.0\n",
      "          WKNF.WI             101.0\n",
      "          废弃2868001.WI       3532.0\n",
      "          废弃868001.WI        3587.0\n",
      "Name: stock_num, Length: 2563801, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_dic['data']['stock_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_INFO_WINDCODE\n",
      "866005.WI    5.297224e+05\n",
      "866006.WI    8.902616e+05\n",
      "866007.WI    8.677217e+05\n",
      "866008.WI    1.112506e+06\n",
      "866009.WI    1.076683e+06\n",
      "866010.WI    9.227805e+05\n",
      "866011.WI    8.237507e+05\n",
      "866012.WI    8.592386e+05\n",
      "866013.WI    4.442092e+05\n",
      "866014.WI    5.274845e+05\n",
      "866015.WI    4.888486e+05\n",
      "866016.WI    3.949548e+05\n",
      "866017.WI    5.626577e+05\n",
      "866018.WI    5.679139e+05\n",
      "866020.WI    1.622899e+05\n",
      "866021.WI    1.675780e+05\n",
      "866022.WI    3.350005e+05\n",
      "866023.WI    1.671567e+05\n",
      "866025.WI    5.770790e+05\n",
      "866026.WI    1.293447e+06\n",
      "Name: S_DQ_VOLUME, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = df_dic['data']\n",
    "print(data['S_DQ_VOLUME'][20171009][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取股票每日收盘价  \n",
    "data:20171009--yesterday  \n",
    "stock_nums:5072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ./data_daily.h5...\n",
      "InstrumentID  SZ300012   SZ002316  SH603856   SZ300177  SH600567  SH688215  \\\n",
      "date                                                                         \n",
      "20171009      4.539998  13.790006       NaN  12.800000  5.420005       NaN   \n",
      "20171010      4.729998  13.550000       NaN  12.550000  5.270005       NaN   \n",
      "20171011      4.639998  13.319988       NaN  12.750000  4.909990       NaN   \n",
      "20171012      4.560002  13.359994       NaN  12.450000  4.940010       NaN   \n",
      "20171013      4.700000  13.309994       NaN  12.260005  4.929995       NaN   \n",
      "\n",
      "InstrumentID   SZ002647   SZ002668   SH600658   SH601116  ...  SH600715  \\\n",
      "date                                                      ...             \n",
      "20171009      35.900000  20.179986  11.039991  27.060018  ...     22.47   \n",
      "20171010      35.950022  20.400000  11.039991  28.639982  ...     22.47   \n",
      "20171011      35.950022  20.879986  10.970007  27.939982  ...     22.47   \n",
      "20171012      35.930022  21.110007  10.949989  29.539982  ...     22.47   \n",
      "20171013      35.880000  20.900000  10.839991  29.710018  ...     22.47   \n",
      "\n",
      "InstrumentID  SH688677  SZ002310   SZ300422  SH600617  SH688003  SZ300816  \\\n",
      "date                                                                        \n",
      "20171009           NaN     21.18  18.760004  9.070001       NaN       NaN   \n",
      "20171010           NaN     21.20  19.169998  9.060001       NaN       NaN   \n",
      "20171011           NaN     21.30  19.120008  8.980000       NaN       NaN   \n",
      "20171012           NaN     20.55  18.779992  8.960001       NaN       NaN   \n",
      "20171013           NaN     21.16  20.660004  9.000000       NaN       NaN   \n",
      "\n",
      "InstrumentID  SZ001260  SZ300136  SH603230  \n",
      "date                                        \n",
      "20171009           NaN     42.57       NaN  \n",
      "20171010           NaN     41.80       NaN  \n",
      "20171011           NaN     41.80       NaN  \n",
      "20171012           NaN     42.75       NaN  \n",
      "20171013           NaN     46.18       NaN  \n",
      "\n",
      "[5 rows x 5072 columns]\n"
     ]
    }
   ],
   "source": [
    "from DataDaily import DataDaily\n",
    "from DataDaily_index_new import DataDaily_index\n",
    "import pandas as pd\n",
    "\n",
    "data_daily = DataDaily()\n",
    "# data_new_index = DataDaily_index()\n",
    "\n",
    "def adj_data(data_list, data=data_daily):\n",
    "    u = data.universe_all\n",
    "    u = list(set(u).intersection(set(data_list.columns)))\n",
    "    return data_list.loc[:, u]\n",
    "\n",
    "close = adj_data(data_daily.close)\n",
    "shift_close = close.shift(-1)\n",
    "\n",
    "print(close.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "20171009     527.770004\n",
      "20171010     540.060006\n",
      "20171011     545.539994\n",
      "20171012     544.090001\n",
      "20171013     556.149993\n",
      "               ...     \n",
      "20240712    1478.820000\n",
      "20240715    1474.900000\n",
      "20240716    1476.000000\n",
      "20240717    1501.400000\n",
      "20240718    1497.510000\n",
      "Name: SH600519, Length: 1648, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(close['SH600519'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_daily.zz500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstrumentID\n",
      "SZ001213     957\n",
      "SZ002386       0\n",
      "SZ002155       0\n",
      "SZ301297    1274\n",
      "SH601658     531\n",
      "            ... \n",
      "SZ300200       0\n",
      "SZ002912      31\n",
      "SH603557       0\n",
      "SH601177       0\n",
      "SH600831       1\n",
      "Length: 5072, dtype: int64\n",
      "InstrumentID\n",
      "SZ001213     957\n",
      "SZ301297    1274\n",
      "SH601658     531\n",
      "SZ003017     741\n",
      "SZ000637       3\n",
      "            ... \n",
      "SZ301128     995\n",
      "SZ301095    1175\n",
      "SH688272     979\n",
      "SZ002912      31\n",
      "SH600831       1\n",
      "Length: 2251, dtype: int64\n",
      "Index(['SZ001213', 'SZ301297', 'SH601658', 'SZ003017', 'SZ000637', 'SZ002477',\n",
      "       'SZ300947', 'SZ301198', 'SH603121', 'SZ002141',\n",
      "       ...\n",
      "       'SZ001333', 'SH600989', 'SZ301196', 'SZ000629', 'SZ300915', 'SZ301128',\n",
      "       'SZ301095', 'SH688272', 'SZ002912', 'SH600831'],\n",
      "      dtype='object', name='InstrumentID', length=2251)\n",
      "date\n",
      "20190111    16.980000\n",
      "20190114    18.680000\n",
      "20190115    20.550000\n",
      "20190116    22.610000\n",
      "20190117    24.870000\n",
      "              ...    \n",
      "20240711    14.175356\n",
      "20240712    14.195154\n",
      "20240715    13.878386\n",
      "20240716    13.878386\n",
      "20240717    13.442831\n",
      "Name: SH603121, Length: 1337, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "close_isna = close.isna().sum() # 每只股票缺失天数总和\n",
    "close_na_stock = close_isna[close_isna > 0].index #有缺失值的股票列表\n",
    "\n",
    "print(close_isna)\n",
    "print(close_isna[close_isna > 0])\n",
    "print(close_na_stock)\n",
    "\n",
    "num = 8\n",
    "print(close[close_na_stock[num]][close[close_na_stock[num]] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40418221879824323\n",
      "17.969141475661793\n",
      "62.7526894603777\n",
      "13.572180663545174\n",
      "0.19070683508202885\n",
      "261.5782028215462\n",
      "50.500112253074974\n",
      "11496.630156509478\n",
      "451.82298325497425\n",
      "12.830965425166104\n",
      "1.7291712313741043e-26\n"
     ]
    }
   ],
   "source": [
    "# 检测方差\n",
    "for i in range(10):\n",
    "    print(close[close.columns[i]].var())\n",
    "\n",
    "print(close['SH600253'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SH600627', 'SZ000033', 'SH601299', 'SZ000406', 'SH600840', 'SH600003',\n",
      "       'SH600991', 'SZ000527', 'SZ300186', 'SH601268', 'SH600296', 'SH600472',\n",
      "       'SH600591', 'SZ000569', 'SH600631', 'SH600253', 'SZ000562', 'SH600002',\n",
      "       'SZ000602', 'SZ000618', 'SZ000578', 'SZ000787', 'SZ000956', 'SZ000866',\n",
      "       'SH600001', 'SZ000549', 'SZ000748', 'SH600205', 'SH600842', 'SH600102',\n",
      "       'SZ000763', 'SZ000594', 'SH600786', 'SZ000522', 'SH600553', 'SH600832',\n",
      "       'SH600607', 'SH600656', 'SZ000817', 'SZ000515', 'SZ000805', 'SH600263',\n",
      "       'SH600005', 'SZ000024', 'SZ300372', 'SH600357'],\n",
      "      dtype='object', name='InstrumentID')\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# 检测退市股票\n",
    "var = close.var()\n",
    "close_not_mkt = var[var < 1e-4].index # 检测出退市的股票代码\n",
    "print(close_not_mkt)\n",
    "print(len(close_not_mkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var = close.var()\n",
    "# close_not_mkt = var[var < 0.1].index # 检测出退市的股票代码\n",
    "# print(len(close_not_mkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "20171009    66.826\n",
      "20171010    66.826\n",
      "20171011    66.826\n",
      "20171012    66.826\n",
      "20171013    66.826\n",
      "             ...  \n",
      "20240711       NaN\n",
      "20240712       NaN\n",
      "20240715       NaN\n",
      "20240716       NaN\n",
      "20240717       NaN\n",
      "Name: SH600627, Length: 1647, dtype: float64\n",
      "4.852289410114506e-25\n",
      "date\n",
      "20171009    4.3843\n",
      "20171010    4.3843\n",
      "20171011    4.3843\n",
      "20171012    4.3843\n",
      "20171013    4.3843\n",
      "             ...  \n",
      "20240711       NaN\n",
      "20240712       NaN\n",
      "20240715       NaN\n",
      "20240716       NaN\n",
      "20240717       NaN\n",
      "Name: SZ000033, Length: 1647, dtype: float64\n",
      "1.895425550825979e-27\n",
      "date\n",
      "20171009    34.6869\n",
      "20171010    34.6869\n",
      "20171011    34.6869\n",
      "20171012    34.6869\n",
      "20171013    34.6869\n",
      "             ...   \n",
      "20240711        NaN\n",
      "20240712        NaN\n",
      "20240715        NaN\n",
      "20240716        NaN\n",
      "20240717        NaN\n",
      "Name: SH601299, Length: 1647, dtype: float64\n",
      "2.2680057436488983e-25\n",
      "date\n",
      "20171009    52.9782\n",
      "20171010    52.9782\n",
      "20171011    52.9782\n",
      "20171012    52.9782\n",
      "20171013    52.9782\n",
      "             ...   \n",
      "20240711        NaN\n",
      "20240712        NaN\n",
      "20240715        NaN\n",
      "20240716        NaN\n",
      "20240717        NaN\n",
      "Name: SZ000406, Length: 1647, dtype: float64\n",
      "1.0187584721527375e-24\n",
      "date\n",
      "20171009    177.072\n",
      "20171010    177.072\n",
      "20171011    177.072\n",
      "20171012    177.072\n",
      "20171013    177.072\n",
      "             ...   \n",
      "20240711        NaN\n",
      "20240712        NaN\n",
      "20240715        NaN\n",
      "20240716        NaN\n",
      "20240717        NaN\n",
      "Name: SH600840, Length: 1647, dtype: float64\n",
      "4.426355001086712e-23\n",
      "date\n",
      "20171009    5.4838\n",
      "20171010    5.4838\n",
      "20171011    5.4838\n",
      "20171012    5.4838\n",
      "20171013    5.4838\n",
      "             ...  \n",
      "20240711       NaN\n",
      "20240712       NaN\n",
      "20240715       NaN\n",
      "20240716       NaN\n",
      "20240717       NaN\n",
      "Name: SH600003, Length: 1647, dtype: float64\n",
      "6.189144655758299e-28\n",
      "date\n",
      "20171009    33.5016\n",
      "20171010    33.5016\n",
      "20171011    33.5016\n",
      "20171012    33.5016\n",
      "20171013    33.5016\n",
      "             ...   \n",
      "20240711        NaN\n",
      "20240712        NaN\n",
      "20240715        NaN\n",
      "20240716        NaN\n",
      "20240717        NaN\n",
      "Name: SH600991, Length: 1647, dtype: float64\n",
      "4.852289410114506e-25\n",
      "date\n",
      "20171009    602.5796\n",
      "20171010    602.5796\n",
      "20171011    602.5796\n",
      "20171012    602.5796\n",
      "20171013    602.5796\n",
      "              ...   \n",
      "20240711         NaN\n",
      "20240712         NaN\n",
      "20240715         NaN\n",
      "20240716         NaN\n",
      "20240717         NaN\n",
      "Name: SZ000527, Length: 1647, dtype: float64\n",
      "3.6071769924846904e-22\n",
      "date\n",
      "20171009    104.6988\n",
      "20171010    104.6988\n",
      "20171011    104.6988\n",
      "20171012    104.6988\n",
      "20171013    104.6988\n",
      "              ...   \n",
      "20240711         NaN\n",
      "20240712         NaN\n",
      "20240715         NaN\n",
      "20240716         NaN\n",
      "20240717         NaN\n",
      "Name: SZ300186, Length: 1647, dtype: float64\n",
      "1.2934049239788772e-26\n",
      "date\n",
      "20171009    2.3594\n",
      "20171010    2.3594\n",
      "20171011    2.3594\n",
      "20171012    2.3594\n",
      "20171013    2.3594\n",
      "             ...  \n",
      "20240711       NaN\n",
      "20240712       NaN\n",
      "20240715       NaN\n",
      "20240716       NaN\n",
      "20240717       NaN\n",
      "Name: SH601268, Length: 1647, dtype: float64\n",
      "1.8569407546565636e-27\n",
      "7.9169407686248645e-22\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(close[close_not_mkt[i]])\n",
    "    print(var[close_not_mkt[i]])\n",
    "\n",
    "print(sum(var[i] for i in close_not_mkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647\n",
      "1383\n"
     ]
    }
   ],
   "source": [
    "print(len(close['SH600253']))\n",
    "print(len(close['SH600253'][close['SH600253'] == close['SH600253'].values[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遗传算法自动挖掘因子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以遗传算法为基本框架，采用自定义运算，来进行后一交易日的收益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gplearn\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from gplearn.fitness import make_fitness\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rank(X):\n",
    "    '''返回X向量中每个元素在X中的分位数'''\n",
    "    X = pd.Series(X)\n",
    "    ranks = X.rank(method='min')\n",
    "    percent = (ranks - 1) / (len(X) -1 )\n",
    "    return percent\n",
    "\n",
    "def _delay(X, d):\n",
    "    '''返回向量X前d天的值'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        X = pd.Series(X)\n",
    "        return X.shift(d)\n",
    "    \n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in delay function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in delay function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "\n",
    "def _corr_d(X, Y, d):\n",
    "    '''计算X,Y最近d天构成的时序列的相关系数'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "    \n",
    "        X, Y = pd.Series(X), pd.Series(Y)\n",
    "        if len(X) != len(Y):\n",
    "            raise ValueError('X and Y have length error')\n",
    "        \n",
    "        return X.rolling(d).corr(Y.rolling(d))\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in corr_d function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in corr_d function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _cov_d(X, Y, d):\n",
    "    '''计算X,Y最近d天构成的时序列的协方差'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "    \n",
    "        X, Y = pd.Series(X), pd.Series(Y)\n",
    "        if len(X) != len(Y):\n",
    "            raise ValueError('X and Y have length error')\n",
    "        \n",
    "        return X.rolling(d).cov(Y.rolling(d))\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in cov_d function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in cov_d function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _scale(X, a):\n",
    "    '''返回 a*X / sum(abs(X)), a的缺省值为1,a一般大于0'''\n",
    "    try:\n",
    "        a = float(a)\n",
    "        X = pd.Series(X)\n",
    "        if not isinstance(a, float):\n",
    "            raise TypeError(\"d must be a float.\")\n",
    "        \n",
    "        return a*X / np.sum(np.abs(X))\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in scale function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scale function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _delta(X, d):\n",
    "    '''返回 X.diff(d)'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        X = pd.Series(X)\n",
    "        return X.diff(d)\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in delta function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in delta function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _signed_power(X, a):\n",
    "    '''保留符号乘方'''\n",
    "    try:\n",
    "        a = float(a)\n",
    "        X = pd.Series(X)\n",
    "        if not isinstance(a, float):\n",
    "            raise TypeError(\"d must be a float.\")\n",
    "        \n",
    "        return np.sign(X) * np.power((np.abs(X)), a)\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in signed_power function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in signed_power function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _decay_linear(X, d):\n",
    "    '''d天线性加权值,权重依靠距今日期做衰减 d, d-1, .... 加权和使用当天数据'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        X = pd.Series(X)\n",
    "        def dot_d(X, d):\n",
    "            X_d = X.iloc[-d:]\n",
    "            weight = np.arange(1, d+1, 1) / np.sum(np.arange(1, d+1, 1))\n",
    "            return np.dot(X_d, weight)\n",
    "        \n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(d-1, len(X)):\n",
    "            res.iloc[i] = dot_d(X.iloc[i-d+1:i+1], d)\n",
    "    \n",
    "        return res\n",
    "    \n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in decay_linear function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in decay_linear function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "\n",
    "def _ind_neutralize(X, inclass):\n",
    "    '''因子行业中性化'''\n",
    "    pass\n",
    "\n",
    "def _ts_min(X, d):\n",
    "    ''' -> array 过去d天最小时序值, 包含当天值'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        X = pd.Series(X)\n",
    "        return X.rolling(d).min()\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in ts_min function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ts_min function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _ts_max(X, d):\n",
    "    ''' -> array 过去d天最大时序值, 包含当天值'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        X = pd.Series(X)\n",
    "        return X.rolling(d).max()\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in ts_max function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ts_max function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _ts_argmin(X, d):\n",
    "    ''' -> array 过去d天最小时序值索引, 包含当天值'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(1, len(X)):\n",
    "            if i < d:\n",
    "                res.iloc[i] = X[:i+1].idxmax()\n",
    "            else:\n",
    "                res.iloc[i] = X[i-d+1:i+1].idxmax()\n",
    "\n",
    "        return res\n",
    "    \n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in ts_argmax function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ts_argmax function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _ts_argmax(X, d):\n",
    "    ''' -> array 过去d天最小时序值索引, 包含当天值'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(1, len(X)):\n",
    "            if i < d:\n",
    "                res.iloc[i] = X[:i+1].idxmin()\n",
    "            else:\n",
    "                res.iloc[i] = X[i-d+1:i+1].idxmin()\n",
    "                \n",
    "        return res\n",
    "    \n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in ts_argmin function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ts_argmin function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _ts_rank(X, d):\n",
    "    '''索引i -> 在i - i-d时间段这个数组中, i的分位值'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(d-1, len(X)):\n",
    "            ranks = X[i-d+1:i+1].rank(method='min')\n",
    "            res.iloc[i] = (ranks.iloc[-1] - 1) / (d - 1)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in ts_rank function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ts_rank function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _ts_sum(X, d):\n",
    "    '''索引i -> i位置的过去d天的时序和'''\n",
    "    try:\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "\n",
    "        return X.rolling(d).sum()\n",
    "    \n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in ts_sum function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ts_sum function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "\n",
    "def _ts_product(X, d):\n",
    "    '''前i天的连乘'''\n",
    "    res = pd.Series(index=X.index)\n",
    "    for i in range(d-1, len(X)):\n",
    "        res.iloc[i] = X[i-d+1:i+1].prod()\n",
    "\n",
    "    return res\n",
    "\n",
    "def _ts_std(X, d):\n",
    "    '''前i天的标准差'''\n",
    "    res = pd.Series(index=X.index)\n",
    "    for i in range(d-1, len(X)):\n",
    "        res.iloc[i] = X[i-d+1:i+1].std()\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "封装块辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_try_except(*args):\n",
    "    '''\n",
    "    封装块 try-except\n",
    "    Parameters:\n",
    "    f: function;\n",
    "    X:array; \n",
    "    d:int or float; \n",
    "    (Y:array) \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        f, X, d = args[0], args[1], args[2]\n",
    "        if len(args) == 3:\n",
    "            return f(X, d)\n",
    "        else:\n",
    "            Y = args[3]\n",
    "            return f(X, Y, d)\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in {f.__name__} function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {f.__name__} function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    \n",
    "def test_Xd(X, d):\n",
    "    '''\n",
    "    封装代码 \n",
    "    检测以及标准化X,d\n",
    "    Parameters:\n",
    "    X:array\n",
    "    d:int\n",
    "    '''\n",
    "\n",
    "    X = pd.Series(X)\n",
    "    d = int(d)  # transform d to int\n",
    "    if not isinstance(d, int) or d < 0:\n",
    "        raise TypeError(\"d must be a non-negative integer.\")\n",
    "    \n",
    "    return X, d\n",
    "\n",
    "def test_Xa(X, a):\n",
    "    '''\n",
    "    封装代码\n",
    "    检测以及标准化X,a\n",
    "    Parameters:\n",
    "    X:array\n",
    "    a:float\n",
    "    '''\n",
    "        \n",
    "    X = pd.Series(X)\n",
    "    a = float(a)\n",
    "    if not isinstance(a, float):\n",
    "        raise TypeError(\"d must be a float.\")\n",
    "    \n",
    "    return X, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rank(X):\n",
    "    '''返回X向量中每个元素在X中的分位数'''\n",
    "    X = pd.Series(X)\n",
    "    ranks = X.rank(method='min')\n",
    "    percent = (ranks - 1) / (len(X) -1 )\n",
    "    return percent\n",
    "\n",
    "def _delay(X, d):\n",
    "    '''返回向量X前d天的值'''\n",
    "    X, d = test_Xd(X, d)\n",
    "\n",
    "    def insert_f(X,d):\n",
    "        return X.shift(d)\n",
    "    \n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _corr_d(X, Y, d):\n",
    "    '''计算X,Y最近d天构成的时序列的相关系数'''\n",
    "    _, d = test_Xd([], d) # only test d\n",
    "    X, Y = pd.Series(X), pd.Series(Y)\n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError('X and Y have length error')\n",
    "    \n",
    "    def insert_f(X, Y, d):\n",
    "        return X.rolling(d).corr(Y.rolling(d))\n",
    "\n",
    "    return my_try_except(insert_f, X, d, Y)\n",
    "\n",
    "def _cov_d(X, Y, d):\n",
    "    '''计算X,Y最近d天构成的时序列的协方差'''\n",
    "    _, d = test_Xd([], d) # only test d\n",
    "    X, Y = pd.Series(X), pd.Series(Y)\n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError('X and Y have length error')\n",
    "    \n",
    "    def insert_f(X, Y, d):\n",
    "        return X.rolling(d).cov(Y.rolling(d))\n",
    "\n",
    "    return my_try_except(insert_f, X, d, Y)\n",
    "\n",
    "\n",
    "def _signed_power(X, a):\n",
    "    '''保留符号乘方'''\n",
    "    X, a = test_Xa(X, a)\n",
    "    def insert_f(X, a):\n",
    "        return np.sign(X) * np.power((np.abs(X)), a)\n",
    "    \n",
    "    return my_try_except(insert_f, X, a)\n",
    "\n",
    "def _scale(X, a):\n",
    "    '''返回 a*X / sum(abs(X)), a的缺省值为1,a一般大于0'''\n",
    "    X, a = test_Xa(X, a)\n",
    "    def insert_f(X, a):\n",
    "        return a*X / np.sum(np.abs(X))\n",
    "    \n",
    "    return my_try_except(insert_f, X, a)\n",
    "\n",
    "def _delta(X, d):\n",
    "    '''返回 X.diff(d)'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        return X.diff(d)\n",
    "    \n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _decay_linear(X, d):\n",
    "    '''d天线性加权值,权重依靠距今日期做衰减 d, d-1, .... 加权和使用当天数据'''\n",
    "    X, d = test_Xd(X, d)\n",
    "\n",
    "    def insert_f(X, d):\n",
    "        def dot_d(X, d):\n",
    "            X_d = X.iloc[-d:]\n",
    "            weight = np.arange(1, d+1, 1) / np.sum(np.arange(1, d+1, 1))\n",
    "            return np.dot(X_d, weight)\n",
    "        \n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(d-1, len(X)):\n",
    "            res.iloc[i] = dot_d(X.iloc[i-d+1:i+1], d)\n",
    "    \n",
    "        return res\n",
    "    \n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_min(X, d):\n",
    "    '''-> array 获取最近d天最小值 '''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        return X.rolling(d).min()\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_max(X, d):\n",
    "    '''-> array 获取最近d天最大值 '''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        return X.rolling(d).max()\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_argmin(X, d):\n",
    "    ''' -> array 过去d天最小时序值索引, 包含当天值'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(1, len(X)):\n",
    "            if i < d:\n",
    "                res.iloc[i] = X[:i+1].idxmax()\n",
    "            else:\n",
    "                res.iloc[i] = X[i-d+1:i+1].idxmax()\n",
    "\n",
    "        return res\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_argmax(X, d):\n",
    "    ''' -> array 过去d天最大时序值索引, 包含当天值'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(1, len(X)):\n",
    "            if i < d:\n",
    "                res.iloc[i] = X[:i+1].idxmin()\n",
    "            else:\n",
    "                res.iloc[i] = X[i-d+1:i+1].idxmin()\n",
    "\n",
    "        return res\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_rank(X, d):\n",
    "    '''索引i -> 在i - i-d时间段这个数组中, i的分位值'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        res = pd.Series(index=X.index)\n",
    "        for i in range(d-1, len(X)):\n",
    "            ranks = X[i-d+1:i+1].rank(method='min')\n",
    "            res.iloc[i] = (ranks.iloc[-1] - 1) / (d - 1)\n",
    "\n",
    "        return res\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_sum(X, d):\n",
    "    '''索引i -> i位置的过去d天的时序和'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        return X.rolling(d).sum()\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_prod(X, d):\n",
    "    '''索引i -> i位置的过去d天的时序乘积'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        return X.rolling(d).prod()\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "def _ts_std(X, d):\n",
    "    '''索引i -> i位置的过去d标准差'''\n",
    "    X, d = test_Xd(X, d)\n",
    "    def insert_f(X, d):\n",
    "        return X.rolling(d).std()\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# nums1 = pd.Series([1, 1, 2, 1])\n",
    "# print(nums1.corr(nums1.copy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    3\n",
      "2    4\n",
      "3    1\n",
      "4   -1\n",
      "5    0\n",
      "dtype: int64\n",
      "0         NaN\n",
      "1    0.707107\n",
      "2    0.707107\n",
      "3    2.121320\n",
      "4    1.414214\n",
      "5    0.707107\n",
      "dtype: float64\n",
      "0    2\n",
      "1    3\n",
      "2    4\n",
      "3    1\n",
      "4   -1\n",
      "5    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-38413047b7cf>:143: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  res = pd.Series(index=X.index)\n"
     ]
    }
   ],
   "source": [
    "nums = pd.Series([2, 3, 4, 1, -1, 0])\n",
    "# nums2 = nums.copy()\n",
    "# print(_delay(nums, 1))\n",
    "# print(_corr_d(nums, nums2, 3))\n",
    "# print(_signed_power(nums, 2))\n",
    "# print(np.arange(1, 5, 1))\n",
    "# print(nums[:2])\n",
    "# print(_delay_linear(nums, 2))\n",
    "# print(nums[:1])\n",
    "print(nums)\n",
    "print(_ts_std(nums, 2))\n",
    "print(pd.Series(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "supplied function delay does not support arity of 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/aglv/anaconda3/lib/python3.8/site-packages/gplearn/functions.py\u001b[0m in \u001b[0;36mmake_function\u001b[0;34m(function, name, arity, wrap)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-042f536d0353>\u001b[0m in \u001b[0;36m_delay\u001b[0;34m(X, d)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m'''返回向量X前d天的值'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_Xd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-005714525b4a>\u001b[0m in \u001b[0;36mtest_Xd\u001b[0;34m(X, d)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# transform d to int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c6e06810572e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'delay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorr_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_corr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'corr_d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcov_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_cov_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cov_d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aglv/anaconda3/lib/python3.8/site-packages/gplearn/functions.py\u001b[0m in \u001b[0;36mmake_function\u001b[0;34m(function, name, arity, wrap)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         raise ValueError('supplied function %s does not support arity of %d.'\n\u001b[0m\u001b[1;32m     97\u001b[0m                          % (name, arity))\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: supplied function delay does not support arity of 2."
     ]
    }
   ],
   "source": [
    "rank = make_function(function=_rank, name='rank', arity=1, wrap=False)\n",
    "delay = make_function(function=_delay, name='delay', arity=2, wrap=False)\n",
    "corr_d = make_function(function=_corr_d, name='corr_d', arity=3, wrap=False)\n",
    "cov_d = make_function(function=_cov_d, name='cov_d', arity=3, wrap=False)\n",
    "scale = make_function(function=_scale, name='scale', arity=2, wrap=False)\n",
    "delta = make_function(function=_delta, name='delta', arity=2, wrap=False)\n",
    "signed_power = make_function(function=_signed_power, name='signed_power', arity=2, wrap=False)\n",
    "# ind_neutralize = make_function(function=_ind_neutralize, name='ind_neutralize', arity=2, wrap=False)\n",
    "decay_linear = make_function(function=_decay_linear, name='decay_linear', arity=2, wrap=False)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=2, wrap=False)\n",
    "ts_max = make_function(function=_ts_max, name='ts_max', arity=2, wrap=False)\n",
    "ts_argmin = make_function(function=_ts_argmin, name='ts_argmin', arity=2, wrap=False)\n",
    "ts_argmax = make_function(function=_ts_argmax, name='ts_argmax', arity=2, wrap=False)\n",
    "ts_rank = make_function(function=_ts_rank, name='ts_rank', arity=2, wrap=False)\n",
    "ts_sum = make_function(function=_ts_sum, name='ts_sum', arity=2, wrap=False)\n",
    "ts_product = make_function(function=_ts_product, name='ts_product', arity=2,wrap=False)\n",
    "ts_std = make_function(function=_ts_std, name='ts_std', arity=2, wrap=False)\n",
    "\n",
    "user_func = [rank, delay, corr_d, cov_d, scale, delta, signed_power, decay_linear,\n",
    "             ts_min, ts_max, ts_argmin, ts_argmax, ts_rank, ts_sum, ts_product, ts_std]\n",
    "\n",
    "init_func = ['add', 'sub', 'mul', 'div', 'sqrt', 'log', 'inv', 'sin', 'max', 'min']\n",
    "\n",
    "my_func = init_func + user_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "5  1\n",
      "4  2\n",
      "3  3\n",
      "2  4\n",
      "1  5\n",
      "0  6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# print(delay(pd.Series([1, 2, 3, 4], index=[2, 3, 4, 5]), 3))\n",
    "from sklearn.model_selection import train_test_split\n",
    "nums = pd.Series([1,2,3,4,5, 6], index=[5,4,3,2,1, 0])\n",
    "# a = nums.rolling(2)\n",
    "# print(a.mean())\n",
    "# print(corr_d(nums, [3, 1, 2, 4, 2], 3))\n",
    "# print(scale([1, 2, 3], 2))\n",
    "# print(np.power(nums, 2))\n",
    "# nums_train, nums_test = train_test_split(nums, test_size=0.4, shuffle=False)\n",
    "# # print(nums.corr(nums.shift(-1)))\n",
    "# print(nums_train)\n",
    "print(pd.DataFrame(nums))\n",
    "print(isinstance(pd.DataFrame(nums), pd.DataFrame))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_try_except_Xd(f, X, d):\n",
    "#     try:\n",
    "#         return f(X, d)\n",
    "#     except TypeError as e:\n",
    "#         if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "#             print(f\"TypeError in ts_min function: {e}\")\n",
    "#         return np.zeros_like(X)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in ts_min function: {e}\")\n",
    "#         return np.zeros_like(X)\n",
    "def my_try_except(*args):\n",
    "    '''\n",
    "    封装块 try-except\n",
    "    Parameters:\n",
    "    f: function;\n",
    "    X:array; \n",
    "    d:int or float; \n",
    "    (Y:array) \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        f, X, d = args[0], args[1], args[2]\n",
    "        if len(args) == 3:\n",
    "            return f(X, d)\n",
    "        else:\n",
    "            Y = args[3]\n",
    "            return f(X, Y, d)\n",
    "    except TypeError as e:\n",
    "        if not 'only size-1 arrays can be converted to Python scalars'  in str(e):\n",
    "            print(f\"TypeError in {f.__name__} function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {f.__name__} function: {e}\")\n",
    "        return np.zeros_like(X)\n",
    "\n",
    "def _ts_min(X, d):\n",
    "    '''-> array 获取最近d天最小值 '''\n",
    "    def insert_f(X, d):\n",
    "        d = int(d)  # transform d to int\n",
    "        if not isinstance(d, int) or d < 0:\n",
    "            raise TypeError(\"d must be a non-negative integer.\")\n",
    "        \n",
    "        X = pd.Series(X)\n",
    "        return X.rolling(d).min()\n",
    "\n",
    "    return my_try_except(insert_f, X, d)\n",
    "\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    2.0\n",
      "4    3.0\n",
      "3    4.0\n",
      "2    5.0\n",
      "1    NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# f(1, 2, 3, 4)\n",
    "\n",
    "nums = pd.Series([1,2,3,4,5], index=[5,4,3,2,1])\n",
    "print(nums.shift(-1))\n",
    "# print(_ts_min(nums, 2))\n",
    "\n",
    "# def f2(a,b):\n",
    "#     return a+b\n",
    "\n",
    "# def f1(a, b):\n",
    "#     return f2(a, b)\n",
    "\n",
    "# print(f1(1, 2))\n",
    "# def f(*args):\n",
    "#     print(args[-1])\n",
    "    \n",
    "# f(1, 2, 3, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "适应度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _my_metric(X, y):\n",
    "    '''\n",
    "    返回X,y之间的秩相关系数\n",
    "    '''\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError('metirc error:X and y must have the same shapr')\n",
    "    \n",
    "    corr, p = spearmanr(X, y)\n",
    "    \n",
    "    return corr\n",
    "\n",
    "\n",
    "my_metric = make_function(function=_my_metric, name='my_metric', arity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主模型框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == 'main':\n",
    "    \n",
    "    est = SymbolicRegressor(\n",
    "        function_set=my_func,\n",
    "        population_size=1000,\n",
    "        generations=3,\n",
    "        metric=my_metric,\n",
    "        stopping_criteria=0.01,\n",
    "        p_crossover=0.4,\n",
    "        p_subtree_mutation=0.01,\n",
    "        p_hoist_mutation=0,\n",
    "        p_point_mutation=0.01,\n",
    "        p_point_replace=0.4,\n",
    "        parsimony_coefficient=0.01,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
